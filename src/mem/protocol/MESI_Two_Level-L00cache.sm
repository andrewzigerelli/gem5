/*
 * Copyright (c) 1999-2013 Mark D. Hill and David A. Wood
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions are
 * met: redistributions of source code must retain the above copyright
 * notice, this list of conditions and the following disclaimer;
 * redistributions in binary form must reproduce the above copyright
 * notice, this list of conditions and the following disclaimer in the
 * documentation and/or other materials provided with the distribution;
 * neither the name of the copyright holders nor the names of its
 * contributors may be used to endorse or promote products derived from
 * this software without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
 * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

machine(MachineType:L0Cache, "MESI Directory L0 Cache CMP")
 : CacheMemory * L0cache;
   Cycles random_latency := 50;

   // Message Queues
   // From this node's L1 cache TO the network

   // a local L1 -> this L2 bank, currently ordered with directory forwarded requests
   MessageBuffer * buffresponse, network="To", virtual_network="3",
        vnet_type="response";


   // To this node's L1 cache FROM the network
   // a L2 bank -> this L1
   MessageBuffer * buffrequest, network="From", virtual_network="3",
        vnet_type="request";


{
  // STATES
  state_declaration(State, desc="Cache states", default="L0Cache_State_NP") {
    // Base states
    NP, AccessPermission:Invalid, desc="Not present in either cache";
    S, AccessPermission:Read_Only, desc="a L0 cache entry Shared";
    I, AccessPermission:Invalid, desc=",,,";  
  }

  // EVENTS
  enumeration(Event, desc="Cache events") {
    // L0 events
    Load,            desc="Load request from the home processor";
    
  }

  // TYPES

  // CacheEntry
  structure(Entry, desc="...", interface="AbstractCacheEntry" ) {
    State CacheState,        desc="cache state";
    DataBlock DataBlk,       desc="data for the block";
    bool Dirty, default="false",   desc="data is dirty";
    bool isPrefetch, desc="Set if this block was prefetched and not yet accessed";
  }
  

  // Counter Table
 // structure(CounterEntry, desc="...", interface="AbstractCacheEntry") {
 //   Addr address,      desc="entry addr";
 //    int counter1,   desc="counter values";
 // }

 // CounterEntry CounterTable[100];  

  // TBE fields
  structure(TBE, desc="...") {
    Addr addr,              desc="Physical address for this TBE";
    State TBEState,        desc="Transient state";
    DataBlock DataBlk,                desc="Buffer for the data block";
    bool Dirty, default="false",   desc="data is dirty";
    int pendingAcks, default="0", desc="number of pending acks";
  }

  structure(TBETable, external="yes") {
    TBE lookup(Addr);
    void allocate(Addr);
    void deallocate(Addr);
    bool isPresent(Addr);
  }

  TBETable TBEs, template="<L0Cache_TBE>", constructor="m_number_of_TBEs";


  Tick clockEdge();
  Cycles ticksToCycles(Tick t);
  void set_cache_entry(AbstractCacheEntry a);
  void unset_cache_entry();
  void set_tbe(TBE a);
  void unset_tbe();
  void wakeUpBuffers(Addr a);
  void profileMsgDelay(int virtualNetworkType, Cycles c);
  int a;

  // inclusive cache returns L1 entries only
  Entry getCacheEntry(Addr addr), return_by_pointer="yes" {
    return static_cast(Entry, "pointer", L0cache[addr]);
    }

  

  State getState(TBE tbe, Entry cache_entry, Addr addr) {

    if(is_valid(tbe)) {
      return tbe.TBEState;
    } else if (is_valid(cache_entry)) {
      return cache_entry.CacheState;
    }
    return State:NP;
  }

  void setState(TBE tbe, Entry cache_entry, Addr addr, State state) {

    // MUST CHANGE
    if(is_valid(tbe)) {
      tbe.TBEState := state;
    }

    if (is_valid(cache_entry)) {
      cache_entry.CacheState := state;
    }
  }

  AccessPermission getAccessPermission(Addr addr) {
    TBE tbe := TBEs[addr];
    if(is_valid(tbe)) {
      DPRINTF(RubySlicc, "%s\n", L0Cache_State_to_permission(tbe.TBEState));
      return L0Cache_State_to_permission(tbe.TBEState);
    }

    Entry cache_entry := getCacheEntry(addr);
    if(is_valid(cache_entry)) {
      DPRINTF(RubySlicc, "%s\n", L0Cache_State_to_permission(cache_entry.CacheState));
      return L0Cache_State_to_permission(cache_entry.CacheState);
    }

    DPRINTF(RubySlicc, "%s\n", AccessPermission:NotPresent);
    return AccessPermission:NotPresent;
  }

  void functionalRead(Addr addr, Packet *pkt) {
    TBE tbe := TBEs[addr];
    if(is_valid(tbe)) {
      testAndRead(addr, tbe.DataBlk, pkt);
    } else {
      testAndRead(addr, getCacheEntry(addr).DataBlk, pkt);
    }
  }

  int functionalWrite(Addr addr, Packet *pkt) {
    int num_functional_writes := 0;

    TBE tbe := TBEs[addr];
    if(is_valid(tbe)) {
      num_functional_writes := num_functional_writes +
        testAndWrite(addr, tbe.DataBlk, pkt);
      return num_functional_writes;
    }

    num_functional_writes := num_functional_writes +
        testAndWrite(addr, getCacheEntry(addr).DataBlk, pkt);
    return num_functional_writes;
  }

  void setAccessPermission(Entry cache_entry, Addr addr, State state) {
    if (is_valid(cache_entry)) {
      cache_entry.changePermission(L0Cache_State_to_permission(state));
    }
  }

  int getPendingAcks(TBE tbe) {
    return tbe.pendingAcks;
  }

  out_port(responseFromBuff, ResponseMsg, buffresponse);


  // Mandatory Queue betweens Node's CPU and it's L1 caches
  in_port(request_in, RequestMsg, buffrequest, desc="...") {
    if (request_in.isReady(clockEdge())) {
      peek(request_in, RequestMsg) {
        Entry cache_entry := getCacheEntry(in_msg.addr);
        if(is_valid(cache_entry)){
              DPRINTF(RubyCache, "MADE IT HERE WTF\n");
           } else {
            trigger(Event:Load, in_msg.addr, cache_entry,
                    TBEs[in_msg.addr]);    
      }
    }
   }
  }


  // ACTIONS
  action(printrequest, "pf", desc="...") {
     DPRINTF(bufferflag, "i love andrew\n");
    Tick a := clockEdge();
    Cycles b := ticksToCycles(a);
    DPRINTF(bufferflag, "addr L0 cycles, %llx, %d\n", address, b);
    DPRINTF(stallflag, "addr L0 cycles, %llx, %d\n", address, b);
    peek(request_in, RequestMsg) {
       enqueue(responseFromBuff, ResponseMsg, random_latency) {
        out_msg.addr := address;
        out_msg.Type := CoherenceResponseType: DATA;
        out_msg.DataBlk := in_msg.DataBlk;
        out_msg.Dirty := in_msg.Dirty;
        out_msg.Sender := machineID;
        out_msg.Destination.add(in_msg.Requestor);
        out_msg.MessageSize := MessageSizeType:Response_Data;
       }
    }

  }
  action(k_popRequestQueue, "k", desc="Pop request queue.") {
    request_in.dequeue(clockEdge());
  }



  //*****************************************************
  // TRANSITIONS
  //*****************************************************


  transition({NP,I}, Load) {
    printrequest;
    k_popRequestQueue;
  }


}
